//
//  ViewController.swift
//  SpeechSDK-transcribe
//
//  Created by kazunori.aoki on 2021/10/29.
//

import UIKit
import Speech

class ViewController: UIViewController {

    // MARK: UI
    @IBOutlet weak var textView: UITextView!
    @IBOutlet weak var recordButton: UIButton!


    // MARK: Property
    // èªè­˜ã™ã‚‹è¨€èªã‚’è¨­å®š
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: Const.localeJP))!
    // éŸ³å£°èªè­˜ã™ã‚‹ãŸã‚ã®è¦æ±‚
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    // éŸ³å£°èªè­˜ã®é€²è¡ŒçŠ¶æ³ã‚’ç›£è¦–ã™ã‚‹ãŸã‚ã®ã‚¿ã‚¹ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    private var recognitionTask: SFSpeechRecognitionTask?
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°åˆ¶ç´„ã‚’æ§‹æˆã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    private let audioEngine = AVAudioEngine()


    // MARK: Lifecycle
    override func viewDidLoad() {
        super.viewDidLoad()

        // æ‰¿èªã•ã‚Œã‚‹ã¾ã§ã€ç„¡åŠ¹ã«ã™ã‚‹
        recordButton.isEnabled = false
    }

    override func viewDidAppear(_ animated: Bool) {
        super.viewDidAppear(animated)

        speechRecognizer.delegate = self

        requestAuthorization()
    }


    // MARK: IBAction
    @IBAction func tapRecordButton(_ sender: Any) {
        if audioEngine.isRunning {
            audioEngine.stop()
            recognitionRequest?.endAudio()
            recordButton.isEnabled = false
            recordButton.setTitle("Stopping", for: .disabled)
        } else {
            do {
                try startRecording()
                recordButton.setTitle("Stop Recording", for: [])
            } catch {
                recordButton.setTitle("Recording Not Available", for: [])
            }
        }
    }
}


// MARK: - Private
private extension ViewController {

    func requestAuthorization() {

        SFSpeechRecognizer.requestAuthorization { authStatus in

            // MainThreadã§è¡Œã†
            OperationQueue.main.addOperation {
                switch authStatus {
                case .authorized:
                    self.recordButton.isEnabled = true

                case .denied:
                    self.recordButton.isEnabled = false
                    self.recordButton
                        .setTitle("User denied access to speech recognition", for: .disabled)

                case .restricted:
                    self.recordButton.isEnabled = false
                    self.recordButton
                        .setTitle("Speech recognition restricted on this device", for: .disabled)

                case .notDetermined:
                    self.recordButton.isEnabled = false
                    self.recordButton
                        .setTitle("Speech recognition not yet authorized", for: .disabled)

                default:
                    self.recordButton.isEnabled = false
                }
            }
        }
    }

    func startRecording() throws {

        // å®Ÿè¡Œä¸­ã®å ´åˆã¯ã€å‰ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã™ã‚‹
        recognitionTask?.cancel()
        recognitionTask = nil

        // audio session configuration
        let audioSession = AVAudioSession.sharedInstance()
        /*
         ** ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªæ¥å¿ƒã®è¨­å®š **
         - category:  ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå‹•ä½œã€.recorde: ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªéŒ²éŸ³ç”¨
         - mode: ã‚«ãƒ†ã‚´ãƒªã®ç‰¹åˆ¥ãªå‹•ä½œã€ .measurement:ã‚¢ãƒ—ãƒªãŒã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå…¥åŠ›ã¾ãŸã¯å‡ºåŠ›ã®æ¸¬å®šã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ãƒ¢ãƒ¼ãƒ‰ã€‚
         - option: ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã®å‹•ä½œã‚’æŒ‡å®šã™ã‚‹ã€.duckOthers: ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã®å†ç”Ÿä¸­ã«ä»–ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³ã®éŸ³é‡ã‚’ä¸‹ã’ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€‚
         */
        try audioSession.setCategory(.record, mode: .measurement, options: .duckOthers)
        /*
         ** ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æŒ‡å®šã—ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–/éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚’è¨­å®š
         - active: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã®æœ‰ç„¡ï¼ˆé›»è©±ãªã©å„ªå…ˆåº¦ã®é«˜ã„é …ç›®ãŒæ¥ãŸå ´åˆã€å¤±æ•—ã™ã‚‹ï¼‰
            ErrorãŒthrowã•ã‚Œã‚‹ï¼ˆAVAudioSession.ErrorCode.isBusyï¼‰
         - .notifyOthersOnDeactivation: ç„¡åŠ¹ã«ãªã£ãŸã“ã¨ã‚’ã‚·ã‚¹ãƒ†ãƒ ãŒä»–ã®ã‚¢ãƒ—ãƒªã«é€šçŸ¥ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã™
         */
        try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        // ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³å…¥åŠ›ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰
        let inputNode = audioEngine.inputNode

        // éŸ³å£°èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®æ§‹æˆ
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let recognitionRequest = recognitionRequest else {
            fatalError("Unable to create a SFSpeechAudioBufferRecognitionRequest object")
        }
        // ç™ºè©±ã”ã¨ã«ä¸­é–“çµæœã‚’è¿”ã™ã‹
        recognitionRequest.shouldReportPartialResults = true

        // TODO: èªè­˜ã•ã›ã‚‹ãŸã‚ã®æ–‡å­—åˆ—
        recognitionRequest.contextualStrings = ["æ¥µä¸»å¤«é“", "ã”ãã—ã‚…ãµã©ã†", "ãƒ´ã‚¡ã‚¤ã‚ªãƒ¬ãƒƒãƒˆãƒ»ã‚¨ãƒ´ã‚¡ãƒ¼ã‚¬ãƒ¼ãƒ‡ãƒ³"]

        // éŸ³å£°èªè­˜ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«ä¿æŒã™ã‚‹ã‹
        recognitionRequest.requiresOnDeviceRecognition = false

        speechRecognizer.recognitionTask(with: recognitionRequest, delegate: self)

        // èªè­˜ã‚¿ã‚¹ã‚¯ã®ä½œæˆã€ã‚¿ã‚¹ã‚¯ã¸ã®å‚ç…§ã‚’ä¿æŒã—ã€ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        // recognitionTask: èªè­˜ãƒ—ãƒ­ã‚»ã‚¹ã®é–‹å§‹
//        recognitionTask = speechRecognizer
//            .recognitionTask(with: recognitionRequest) { result, error in
//            var isFinal = false
//
//            if let result = result {
//                // textViewã¸ã®åæ˜ 
//                self.textView.text = result.bestTranscription.formattedString
//                isFinal = result.isFinal
////                print("Text: \(result.bestTranscription.formattedString)")
////                print("segment: \(result.bestTranscription.segments)")
////                print("segment: \(result.bestTranscription.segments[0].substring)")
////                print("isFinal: \(result.isFinal)")
//
//                // ç™ºè©±ãŒçµ‚ã‚ã£ã¦ã‹ã‚‰ã®æ™‚é–“
//                if let duration = result.bestTranscription.segments.first?.duration {
////                    print("duration: \(result.bestTranscription.segments.first!.duration)")
//                    print(duration == 0.0 ? "å–‹ã£ã¦ã‚‹" : "å–‹ã£ã¦ãªã„")
//                }
//            }
//
//            // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ1minï¼‰ã‚‚ã“ã“ã«å…¥ã‚‹
//            // ã‚¨ãƒ©ãƒ¼ã®ãªã‹ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒæ ¼ç´ã•ã‚Œã‚‹
//            if error != nil || isFinal {
//                // å•é¡ŒãŒã‚ã£ãŸã‚‰åœæ­¢
//                self.audioEngine.stop()
//                // æŒ‡å®šã—ãŸãƒã‚¹ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¿ãƒƒãƒ—ã‚’å‰Šé™¤ã™ã‚‹
//                inputNode.removeTap(onBus: 0)
//
//                self.recognitionRequest = nil
//                self.recognitionTask = nil
//
//                print("end")
////                print("isFinal: \(result?.isFinal)") // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®å ´åˆnil
//
//                self.recordButton.isEnabled = true
//                self.recordButton.setTitle("Start Recording!", for: [])
//
//                self.textView.text = ""
//            }
//        }

        // ãƒã‚¤ã‚¯è¨­å®š
        // æŒ‡å®šã—ãŸãƒã‚¹ã®å‡ºåŠ›å½¢å¼ã®å–å¾—
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        // æŒ‡å®šã—ãŸãƒã‚¹ã«ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¿ãƒƒãƒ—ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€
        // ãƒãƒ¼ãƒ‰ã®å‡ºåŠ›ã‚’éŒ²éŸ³ã€ç›£è¦–ã™ã‚‹
        inputNode.installTap(onBus: 0,
                             bufferSize: 2048,
                             format: recordingFormat) { (buffer: AVAudioPCMBuffer,
                                                         when: AVAudioTime) in
            // ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ä»¥å¤–ã§å‘¼ã°ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚‹
            self.recognitionRequest?.append(buffer)
        }

        audioEngine.prepare()
        try audioEngine.start()

        // è©±ã—å§‹ã‚ã‚‹åˆå›³
        textView.text = "(Go ahead, I'm listening)"
    }
}


// MARK: - SFSpeechRecognizerDelegate
extension ViewController: SFSpeechRecognizerDelegate {

    // å¯ç”¨æ€§ã®å¤‰æ›´ï¼ˆä½¿ãˆã‚‹ã‚ˆã†ã«ãªã£ãŸã€ä½¿ãˆãªããªã£ãŸï¼‰ã®æ¤œçŸ¥
    func speechRecognizer(_ speechRecognizer: SFSpeechRecognizer,
                          availabilityDidChange available: Bool) {
        if available {
            recordButton.isEnabled = true
            recordButton.setTitle("Start Recording!", for: [])
        } else {
            recordButton.isEnabled = false
            recordButton.setTitle("Recognition Not Available", for: .disabled)
        }
    }

}

extension ViewController: SFSpeechRecognitionTaskDelegate {

    // éŸ³å£°å…¥åŠ›ãŒã‚ã£ãŸã¨ã
    func speechRecognitionTask(_ task: SFSpeechRecognitionTask, didHypothesizeTranscription transcription: SFTranscription) {
        print("ğŸ”°ğŸ”°ğŸ”°speechRecognitionTask transcription")
//        print("task: \(task)")
//        print("transcription: \(transcription)")

        if let duration = transcription.segments.first?.duration {
//                    print("duration: \(result.bestTranscription.segments.first!.duration)")
            print(duration == 0.0 ? "å–‹ã£ã¦ã‚‹" : "å–‹ã£ã¦ãªã„")
        }
    }

    // çµ‚äº†æ¤œçŸ¥
    func speechRecognitionTaskFinishedReadingAudio(_ task: SFSpeechRecognitionTask) {
        print("speechRecognitionTask FinishedReadingAudio")
//        print("task: \(task)")
        /*
         starting = 0
         running = 1
         finishing = 2
         canceling = 3
         completed = 4
         */
        // ã“ã®æ®µéšã§ã¯ã€çµ‚äº†ãƒœã‚¿ãƒ³æŠ¼ä¸‹å¾Œã€runningã«ãªã£ã¦ã„ã‚‹
//        print("state: \(task.state.rawValue)")
//        print("isFinishing: \(task.isFinishing)")
//        print("isCancelled: \(task.isCancelled)")
//        print("error: \(task.error)")
    }

    // çµ‚äº†å¾Œã®
    func speechRecognitionTask(_ task: SFSpeechRecognitionTask, didFinishSuccessfully successfully: Bool) {
        print("speechRecognitionTask successfully")
//        print("successfully: \(successfully)")
//        print("task: \(task)")
        // ã“ã®æ®µéšã§ã¯ã€çµ‚äº†ãƒœã‚¿ãƒ³æŠ¼ä¸‹å¾Œã€completedã«ãªã£ã¦ã„ã‚‹
        print("state: \(task.state.rawValue)")
        print("isFinishing: \(task.isFinishing)")
        print("isCancelled: \(task.isCancelled)")
        print("error: \(task.error?.code) \n \(task.error?.domain) \n \(task.error?.localizedDescription)")
        // TODO: å†ã‚¹ã‚¿ãƒ¼ãƒˆ
    }

    // ã™ã¹ã¦ã®éŸ³å£°å‡ºåŠ›å®Œäº†å¾Œã®å‡ºåŠ›
    func speechRecognitionTask(_ task: SFSpeechRecognitionTask, didFinishRecognition recognitionResult: SFSpeechRecognitionResult) {
        print("speechRecognitionTask recognitionResult")
//        print("recognitionResult: \(recognitionResult)")
//        print("task: \(task)")
    }

    func speechRecognitionTaskWasCancelled(_ task: SFSpeechRecognitionTask) {
        print("speechRecognitionTaskWasCancelled")
//        print("task: \(task)")
    }

    // ã‚½ãƒ¼ã‚¹ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªæ™‚ã®é–‹å§‹æ¤œçŸ¥
    func speechRecognitionDidDetectSpeech(_ task: SFSpeechRecognitionTask) {
        print("speechRecognitionDidDetectSpeech")
//        print("task: \(task)")
    }


}

extension Error {
    var code: Int {
        return (self as NSError).code
    }

    var domain: String {
        return (self as NSError).domain
    }
}
